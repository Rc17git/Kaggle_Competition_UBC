{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":45867,"databundleVersionId":6924515,"sourceType":"competition"},{"sourceId":2781575,"sourceType":"datasetVersion","datasetId":1279557}],"dockerImageVersionId":30626,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/rishabh0517/ubcbaselinetrain?scriptVersionId=157762093\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-25T17:51:19.065035Z","iopub.execute_input":"2023-12-25T17:51:19.065902Z","iopub.status.idle":"2023-12-25T17:51:19.705013Z","shell.execute_reply.started":"2023-12-25T17:51:19.065857Z","shell.execute_reply":"2023-12-25T17:51:19.703682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom tqdm import tqdm\nimport os\nimport cv2\nimport numpy as np\nfrom PIL import Image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils import shuffle\nimport tensorflow as tf\nimport keras\nfrom tensorflow.keras.applications import EfficientNetB0, InceptionV3\nfrom tensorflow.keras.layers import Flatten,Dense,MaxPooling2D\nfrom tensorflow.keras.models import Sequential\nfrom keras.layers import Input, Dense,Conv2D , MaxPooling2D, Flatten,BatchNormalization,Dropout\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report,confusion_matrix\nfrom collections import Counter\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.optim import lr_scheduler\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.cuda import amp\nimport torchvision\nfrom PIL import Image\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.utils import shuffle\nfrom collections import Counter\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom torch.utils.data import Dataset, DataLoader\nimport cv2\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nfrom sklearn.model_selection import StratifiedKFold","metadata":{"execution":{"iopub.status.busy":"2024-01-03T20:56:38.140745Z","iopub.execute_input":"2024-01-03T20:56:38.141016Z","iopub.status.idle":"2024-01-03T20:56:53.265661Z","shell.execute_reply.started":"2024-01-03T20:56:38.140993Z","shell.execute_reply":"2024-01-03T20:56:53.264855Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"df=pd.read_csv('/kaggle/input/UBC-OCEAN/train.csv')","metadata":{"execution":{"iopub.status.busy":"2024-01-03T20:56:53.267227Z","iopub.execute_input":"2024-01-03T20:56:53.267753Z","iopub.status.idle":"2024-01-03T20:56:53.285819Z","shell.execute_reply.started":"2024-01-03T20:56:53.267726Z","shell.execute_reply":"2024-01-03T20:56:53.284916Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train_df_tma = df[df['is_tma']==True]","metadata":{"execution":{"iopub.status.busy":"2024-01-03T20:56:53.28695Z","iopub.execute_input":"2024-01-03T20:56:53.287296Z","iopub.status.idle":"2024-01-03T20:56:53.320218Z","shell.execute_reply.started":"2024-01-03T20:56:53.287271Z","shell.execute_reply":"2024-01-03T20:56:53.319377Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train_df_no_tma = df[df['is_tma']==False]","metadata":{"execution":{"iopub.status.busy":"2024-01-03T20:56:53.322926Z","iopub.execute_input":"2024-01-03T20:56:53.323545Z","iopub.status.idle":"2024-01-03T20:56:53.331061Z","shell.execute_reply.started":"2024-01-03T20:56:53.323514Z","shell.execute_reply":"2024-01-03T20:56:53.330299Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"train_df_no_tma['image_id_path'] = [f\"{i}_thumbnail.png\" for i in train_df_no_tma['image_id']]","metadata":{"execution":{"iopub.status.busy":"2024-01-03T20:56:53.331969Z","iopub.execute_input":"2024-01-03T20:56:53.332259Z","iopub.status.idle":"2024-01-03T20:56:53.342425Z","shell.execute_reply.started":"2024-01-03T20:56:53.332237Z","shell.execute_reply":"2024-01-03T20:56:53.3416Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_42/2494151524.py:1: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  train_df_no_tma['image_id_path'] = [f\"{i}_thumbnail.png\" for i in train_df_no_tma['image_id']]\n","output_type":"stream"}]},{"cell_type":"code","source":"train_df_tma['image_id_path'] = [f\"{i}.png\" for i in train_df_tma['image_id']]","metadata":{"execution":{"iopub.status.busy":"2024-01-03T20:56:53.343612Z","iopub.execute_input":"2024-01-03T20:56:53.343948Z","iopub.status.idle":"2024-01-03T20:56:53.3526Z","shell.execute_reply.started":"2024-01-03T20:56:53.343908Z","shell.execute_reply":"2024-01-03T20:56:53.351785Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_42/1031206012.py:1: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  train_df_tma['image_id_path'] = [f\"{i}.png\" for i in train_df_tma['image_id']]\n","output_type":"stream"}]},{"cell_type":"code","source":"image_data = []\nimage_label = []\nimg_size=150","metadata":{"execution":{"iopub.status.busy":"2024-01-03T20:56:53.353733Z","iopub.execute_input":"2024-01-03T20:56:53.35408Z","iopub.status.idle":"2024-01-03T20:56:53.361951Z","shell.execute_reply.started":"2024-01-03T20:56:53.35405Z","shell.execute_reply":"2024-01-03T20:56:53.361138Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"for img , label in zip(train_df_no_tma['image_id_path'],train_df_no_tma['label']):\n    image = Image.open(\"/kaggle/input/UBC-OCEAN/train_thumbnails/\"+img)\n    image = image.resize((img_size,img_size))\n    image = image.convert(\"RGB\")\n    image = np.array(image)\n    image_data.append(image)\n    image_label.append(label)","metadata":{"execution":{"iopub.status.busy":"2024-01-03T20:56:53.362948Z","iopub.execute_input":"2024-01-03T20:56:53.363242Z","iopub.status.idle":"2024-01-03T20:59:08.474406Z","shell.execute_reply.started":"2024-01-03T20:56:53.363219Z","shell.execute_reply":"2024-01-03T20:59:08.473574Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"for img , label in zip(train_df_tma['image_id_path'],train_df_tma['label']):\n    image = Image.open(\"/kaggle/input/UBC-OCEAN/train_images/\"+img)\n    image = image.resize((img_size,img_size))\n    image = image.convert(\"RGB\")\n    image = np.array(image)\n    image_data.append(image)\n    image_label.append(label)","metadata":{"execution":{"iopub.status.busy":"2024-01-03T20:59:08.475458Z","iopub.execute_input":"2024-01-03T20:59:08.475724Z","iopub.status.idle":"2024-01-03T20:59:23.143285Z","shell.execute_reply.started":"2024-01-03T20:59:08.475702Z","shell.execute_reply":"2024-01-03T20:59:23.142365Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"datagen = ImageDataGenerator(\n        rotation_range=20, # randomly rotate images by 20 degrees\n        width_shift_range=0.2, # randomly shift images horizontally by 20% of the width\n        height_shift_range=0.2, # randomly shift images vertically by 20% of the height\n        horizontal_flip=True, # randomly flip images horizontally\n        zoom_range=0.2)","metadata":{"execution":{"iopub.status.busy":"2024-01-03T20:59:23.147651Z","iopub.execute_input":"2024-01-03T20:59:23.147955Z","iopub.status.idle":"2024-01-03T20:59:23.152509Z","shell.execute_reply.started":"2024-01-03T20:59:23.14793Z","shell.execute_reply":"2024-01-03T20:59:23.15164Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def augment_and_balance_data(image_data, image_label, target_count):\n    datagen = ImageDataGenerator(\n        rotation_range=20,\n        width_shift_range=0.2,\n        height_shift_range=0.2,\n        horizontal_flip=True,\n        zoom_range=0.2\n    )\n\n    # Count the occurrences of each label\n    label_counts = Counter(image_label)\n\n    # Iterate through each label\n    for label, count in label_counts.items():\n        # Calculate the number of augmented images needed for this label\n        num_augmented_images = target_count - count\n\n        # If more images are needed for this label\n        if num_augmented_images > 0:\n            # Find indices of images with the current label\n            indices = [i for i, l in enumerate(image_label) if l == label]\n\n            # Randomly select existing images with this label\n            selected_indices = np.random.choice(indices, num_augmented_images, replace=True)\n\n            # Augment and append the new images and labels\n            for i in selected_indices:\n                img = image_data[i]\n                img = img.reshape((1,) + img.shape)  # Add batch dimension\n                label = image_label[i]\n\n                for batch in datagen.flow(img, batch_size=1):\n                    augmented_image = batch[0]\n                    image_data.append(augmented_image)\n                    image_label.append(label)\n                    break  # Break to avoid infinite loop\n\n# Example usage","metadata":{"execution":{"iopub.status.busy":"2024-01-03T20:59:23.153509Z","iopub.execute_input":"2024-01-03T20:59:23.153763Z","iopub.status.idle":"2024-01-03T20:59:23.165027Z","shell.execute_reply.started":"2024-01-03T20:59:23.15374Z","shell.execute_reply":"2024-01-03T20:59:23.164139Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Assuming you have already loaded image_data and image_label\ntarget_count = max(Counter(image_label).values())\nprint(target_count)# Set target count to the maximum label frequency\naugment_and_balance_data(image_data, image_label, target_count)","metadata":{"execution":{"iopub.status.busy":"2024-01-03T20:59:23.166157Z","iopub.execute_input":"2024-01-03T20:59:23.16649Z","iopub.status.idle":"2024-01-03T20:59:25.999327Z","shell.execute_reply.started":"2024-01-03T20:59:23.166459Z","shell.execute_reply":"2024-01-03T20:59:25.998543Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"222\n","output_type":"stream"}]},{"cell_type":"code","source":"print(len(image_data))\nprint(image_label.count('MC'))","metadata":{"execution":{"iopub.status.busy":"2024-01-03T20:59:26.000346Z","iopub.execute_input":"2024-01-03T20:59:26.000641Z","iopub.status.idle":"2024-01-03T20:59:26.005747Z","shell.execute_reply.started":"2024-01-03T20:59:26.000616Z","shell.execute_reply":"2024-01-03T20:59:26.004794Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"1110\n222\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\n# Assuming image_label is your list of string labels\nlabel_encoder = LabelEncoder()\nencoded_labels = label_encoder.fit_transform(image_label)","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2024-01-03T20:59:26.006975Z","iopub.execute_input":"2024-01-03T20:59:26.007264Z","iopub.status.idle":"2024-01-03T20:59:26.020601Z","shell.execute_reply.started":"2024-01-03T20:59:26.007242Z","shell.execute_reply":"2024-01-03T20:59:26.019841Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"image_data = [np.array(image) for image in image_data]\n\n# Convert image_data and image_label to NumPy arrays\nX = np.array(image_data)\nY = np.array(encoded_labels)","metadata":{"execution":{"iopub.status.busy":"2024-01-03T20:59:26.030431Z","iopub.execute_input":"2024-01-03T20:59:26.03068Z","iopub.status.idle":"2024-01-03T20:59:26.251282Z","shell.execute_reply.started":"2024-01-03T20:59:26.030659Z","shell.execute_reply":"2024-01-03T20:59:26.250504Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"X.shape","metadata":{"execution":{"iopub.status.busy":"2024-01-03T19:11:58.350859Z","iopub.execute_input":"2024-01-03T19:11:58.351591Z","iopub.status.idle":"2024-01-03T19:11:58.357397Z","shell.execute_reply.started":"2024-01-03T19:11:58.351559Z","shell.execute_reply":"2024-01-03T19:11:58.356411Z"},"trusted":true},"execution_count":48,"outputs":[{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"(1110, 224, 224, 3)"},"metadata":{}}]},{"cell_type":"code","source":"datagen.fit(X)\n\n# generate more images using the fitted generator\naugmented_images_a = []\naugmented_labels_a = []\nfor x_batch, y_batch in datagen.flow(X, Y, batch_size=len(X)):\n    augmented_images_a.extend(x_batch)\n    augmented_labels_a.extend(y_batch)\n    break\nfor x_batch, y_batch in datagen.flow(X, Y, batch_size=len(X)):\n    augmented_images_a.extend(x_batch)\n    augmented_labels_a.extend(y_batch)\n    break\nfor x_batch, y_batch in datagen.flow(X, Y, batch_size=len(X)):\n    augmented_images_a.extend(x_batch)\n    augmented_labels_a.extend(y_batch)\n    break\nfor x_batch, y_batch in datagen.flow(X, Y, batch_size=len(X)):\n    augmented_images_a.extend(x_batch)\n    augmented_labels_a.extend(y_batch)\n    break","metadata":{"execution":{"iopub.status.busy":"2024-01-03T20:59:26.252399Z","iopub.execute_input":"2024-01-03T20:59:26.252751Z","iopub.status.idle":"2024-01-03T20:59:45.950486Z","shell.execute_reply.started":"2024-01-03T20:59:26.252719Z","shell.execute_reply":"2024-01-03T20:59:45.949502Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"augmented_images_a = np.array(augmented_images_a)\naugmented_labels_a = np.array(augmented_labels_a)\n\n#concatenate og data with augmented\nX_train = np.concatenate((X, augmented_images_a))\ny_train = np.concatenate((Y, augmented_labels_a))","metadata":{"execution":{"iopub.status.busy":"2024-01-03T20:59:45.951726Z","iopub.execute_input":"2024-01-03T20:59:45.952035Z","iopub.status.idle":"2024-01-03T20:59:46.87287Z","shell.execute_reply.started":"2024-01-03T20:59:45.952009Z","shell.execute_reply":"2024-01-03T20:59:46.871903Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"X_train, y_train = shuffle(X_train,y_train, random_state=101)\nX_train,X_test,y_train,y_test = train_test_split(X_train, y_train, test_size=0.3,random_state=101)","metadata":{"execution":{"iopub.status.busy":"2024-01-03T20:59:46.873924Z","iopub.execute_input":"2024-01-03T20:59:46.87423Z","iopub.status.idle":"2024-01-03T20:59:47.737684Z","shell.execute_reply.started":"2024-01-03T20:59:46.874204Z","shell.execute_reply":"2024-01-03T20:59:47.73669Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"print(X_train.shape)\nprint(y_train.shape)\nprint(X_test.shape)\nprint(y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2024-01-03T20:59:47.738948Z","iopub.execute_input":"2024-01-03T20:59:47.739253Z","iopub.status.idle":"2024-01-03T20:59:47.744588Z","shell.execute_reply.started":"2024-01-03T20:59:47.739227Z","shell.execute_reply":"2024-01-03T20:59:47.743788Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"(3885, 150, 150, 3)\n(3885,)\n(1665, 150, 150, 3)\n(1665,)\n","output_type":"stream"}]},{"cell_type":"code","source":"y_train = tf.keras.utils.to_categorical(y_train)\n\ny_test = tf.keras.utils.to_categorical(y_test)","metadata":{"execution":{"iopub.status.busy":"2024-01-03T20:59:47.745641Z","iopub.execute_input":"2024-01-03T20:59:47.745939Z","iopub.status.idle":"2024-01-03T20:59:47.754755Z","shell.execute_reply.started":"2024-01-03T20:59:47.74591Z","shell.execute_reply":"2024-01-03T20:59:47.754056Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"class GeM(tf.keras.layers.Layer):\n    def __init__(self, p=3, eps=1e-6):\n        super(GeM, self).__init__()\n        self.p = tf.constant(p, dtype=tf.float32)\n        self.eps = eps\n\n    def call(self, x):\n        return self.gem(x, p=self.p, eps=self.eps)\n        \n    def gem(self, x, p=3, eps=1e-6):\n        return tf.pow(tf.reduce_mean(tf.pow(tf.maximum(x, eps), p), axis=[1, 2]), 1.0/p)","metadata":{"execution":{"iopub.status.busy":"2024-01-03T19:12:31.934401Z","iopub.execute_input":"2024-01-03T19:12:31.934761Z","iopub.status.idle":"2024-01-03T19:12:31.942992Z","shell.execute_reply.started":"2024-01-03T19:12:31.934728Z","shell.execute_reply":"2024-01-03T19:12:31.942117Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"import tensorflow_hub as hub\nfrom tensorflow.keras.layers import Lambda\npath1 = '/kaggle/input/keras-applications-models/EfficientNetB0.h5'\neffnet = EfficientNetB0(weights=None, include_top=False, input_shape=(224,224, 3))\neffnet.load_weights(path1)\n# Define the Sequential model\nnum_class = 5\nefficientnet_model = Sequential()\n\n# Add layers to the Sequential model\nefficientnet_model.add(effnet)\nefficientnet_model.add(Dense(units=4096, activation=\"relu\"))\nefficientnet_model.add(Dropout(0.25))\nefficientnet_model.add(Dense(units=4096, activation=\"relu\"))\nefficientnet_model.add(Dropout(0.25))\nefficientnet_model.add(Dense(units=4096, activation=\"relu\"))\nefficientnet_model.add(tf.keras.layers.GlobalAveragePooling2D())\n#efficientnet_model.add(Lambda(lambda x: GeM()(x)))\nefficientnet_model.add(Dropout(0.25))\nefficientnet_model.add(Dense(units=2048, activation=\"relu\"))\nefficientnet_model.add(Dropout(0.25))\nefficientnet_model.add(Dense(units=2048, activation=\"relu\"))\nefficientnet_model.add(Dropout(0.25))\nefficientnet_model.add(Dense(units=1024, activation=\"relu\"))\nefficientnet_model.add(Dropout(0.25))\nefficientnet_model.add(Dense(units=256, activation=\"relu\"))\nefficientnet_model.add(Dropout(0.25))\nefficientnet_model.add(Dense(units=num_class, activation=\"softmax\"))","metadata":{"execution":{"iopub.status.busy":"2024-01-03T19:39:55.388882Z","iopub.execute_input":"2024-01-03T19:39:55.389192Z","iopub.status.idle":"2024-01-03T19:40:00.242895Z","shell.execute_reply.started":"2024-01-03T19:39:55.389154Z","shell.execute_reply":"2024-01-03T19:40:00.24209Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"path1 = '/kaggle/input/keras-applications-models/EfficientNetB0.h5'\neffnet = EfficientNetB0(weights=None, include_top=False, input_shape=(150, 150, 3))\neffnet.load_weights(path1)\n# Define the Sequential model\nnum_class = 5\nefficientnet_model = Sequential()\n\n# Add layers to the Sequential model\nefficientnet_model.add(effnet)\nefficientnet_model.add(Dense(units=1024, activation=\"relu\"))\nefficientnet_model.add(Dropout(0.25))\nefficientnet_model.add(tf.keras.layers.GlobalAveragePooling2D())\n#efficientnet_model.add(Lambda(lambda x: GeM()(x)))\nefficientnet_model.add(Dense(units=256, activation=\"relu\"))\nefficientnet_model.add(Dense(units=256, activation=\"relu\"))\nefficientnet_model.add(Dense(units=256, activation=\"relu\"))\nefficientnet_model.add(Dropout(0.25))\nefficientnet_model.add(Dense(units=64, activation=\"relu\"))\nefficientnet_model.add(Dense(units=num_class, activation=\"softmax\"))","metadata":{"execution":{"iopub.status.busy":"2024-01-03T21:00:10.572852Z","iopub.execute_input":"2024-01-03T21:00:10.573824Z","iopub.status.idle":"2024-01-03T21:00:13.878562Z","shell.execute_reply.started":"2024-01-03T21:00:10.573788Z","shell.execute_reply":"2024-01-03T21:00:13.877669Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"opt = keras.optimizers.Adam(learning_rate=0.0001)\nefficientnet_model.compile(loss='categorical_crossentropy',  optimizer=opt, metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2024-01-03T21:00:13.880291Z","iopub.execute_input":"2024-01-03T21:00:13.880623Z","iopub.status.idle":"2024-01-03T21:00:13.900485Z","shell.execute_reply.started":"2024-01-03T21:00:13.880595Z","shell.execute_reply":"2024-01-03T21:00:13.899676Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"class SaveBestWeights(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs=None):\n        val_accuracy = logs.get('val_accuracy')\n        val_loss = logs.get('val_loss')\n\n        # Check if validation accuracy and recall are not None\n        if val_accuracy is not None and val_loss is not None:\n            filename = f'best_weights_epoch_{epoch:02d}_val_acc_{val_accuracy:.4f}_val_loss_{val_loss:.4f}.bin'\n            self.model.save_weights(filename, save_format='tf')\n            print(f\"Saved best weights to {filename}\")\n        else:\n            print(f\"Warning: val_accuracy={val_accuracy}, val_loss={val_loss}. Skipping save.\")\n\n# Define a ModelCheckpoint callback to save the best weights based on validation accuracy\nmodel_checkpoint = ModelCheckpoint('tmp_checkpoint.h5', save_best_only=True, monitor='val_accuracy', mode='max', verbose=1)\nsave_best_weights_callback = SaveBestWeights()\n\n# Train the model with the callbacks\nhistory = efficientnet_model.fit(X_train, y_train, validation_split=0.3, epochs=30, verbose=1, batch_size=10)","metadata":{"execution":{"iopub.status.busy":"2024-01-03T21:00:13.901658Z","iopub.execute_input":"2024-01-03T21:00:13.902244Z","iopub.status.idle":"2024-01-03T21:08:26.665872Z","shell.execute_reply.started":"2024-01-03T21:00:13.902212Z","shell.execute_reply":"2024-01-03T21:08:26.664979Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"Epoch 1/30\n","output_type":"stream"},{"name":"stderr","text":"2024-01-03 21:00:31.187022: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_1/efficientnetb0/block2b_drop/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"272/272 [==============================] - 65s 67ms/step - loss: 1.3642 - accuracy: 0.4138 - val_loss: 1.0255 - val_accuracy: 0.5995\nEpoch 2/30\n272/272 [==============================] - 15s 54ms/step - loss: 0.8611 - accuracy: 0.6587 - val_loss: 0.5129 - val_accuracy: 0.8156\nEpoch 3/30\n272/272 [==============================] - 15s 54ms/step - loss: 0.5325 - accuracy: 0.7951 - val_loss: 0.3906 - val_accuracy: 0.8585\nEpoch 4/30\n272/272 [==============================] - 15s 54ms/step - loss: 0.3387 - accuracy: 0.8764 - val_loss: 0.3188 - val_accuracy: 0.8919\nEpoch 5/30\n272/272 [==============================] - 15s 54ms/step - loss: 0.2828 - accuracy: 0.9014 - val_loss: 0.3033 - val_accuracy: 0.9082\nEpoch 6/30\n272/272 [==============================] - 15s 54ms/step - loss: 0.2171 - accuracy: 0.9287 - val_loss: 0.2846 - val_accuracy: 0.9082\nEpoch 7/30\n272/272 [==============================] - 15s 54ms/step - loss: 0.1566 - accuracy: 0.9470 - val_loss: 0.2435 - val_accuracy: 0.9211\nEpoch 8/30\n272/272 [==============================] - 15s 54ms/step - loss: 0.1607 - accuracy: 0.9441 - val_loss: 0.1929 - val_accuracy: 0.9288\nEpoch 9/30\n272/272 [==============================] - 15s 54ms/step - loss: 0.1433 - accuracy: 0.9503 - val_loss: 0.1770 - val_accuracy: 0.9391\nEpoch 10/30\n272/272 [==============================] - 15s 54ms/step - loss: 0.0964 - accuracy: 0.9691 - val_loss: 0.2092 - val_accuracy: 0.9417\nEpoch 11/30\n272/272 [==============================] - 15s 54ms/step - loss: 0.0946 - accuracy: 0.9640 - val_loss: 0.1902 - val_accuracy: 0.9451\nEpoch 12/30\n272/272 [==============================] - 15s 54ms/step - loss: 0.1113 - accuracy: 0.9669 - val_loss: 0.1875 - val_accuracy: 0.9460\nEpoch 13/30\n272/272 [==============================] - 15s 54ms/step - loss: 0.0896 - accuracy: 0.9695 - val_loss: 0.1843 - val_accuracy: 0.9477\nEpoch 14/30\n272/272 [==============================] - 15s 54ms/step - loss: 0.0851 - accuracy: 0.9728 - val_loss: 0.2151 - val_accuracy: 0.9374\nEpoch 15/30\n272/272 [==============================] - 15s 54ms/step - loss: 0.0825 - accuracy: 0.9739 - val_loss: 0.1511 - val_accuracy: 0.9503\nEpoch 16/30\n272/272 [==============================] - 15s 54ms/step - loss: 0.0747 - accuracy: 0.9724 - val_loss: 0.2081 - val_accuracy: 0.9434\nEpoch 17/30\n272/272 [==============================] - 15s 54ms/step - loss: 0.0832 - accuracy: 0.9717 - val_loss: 0.1563 - val_accuracy: 0.9485\nEpoch 18/30\n272/272 [==============================] - 15s 54ms/step - loss: 0.0748 - accuracy: 0.9728 - val_loss: 0.1659 - val_accuracy: 0.9434\nEpoch 19/30\n272/272 [==============================] - 15s 54ms/step - loss: 0.0682 - accuracy: 0.9772 - val_loss: 0.1131 - val_accuracy: 0.9623\nEpoch 20/30\n272/272 [==============================] - 15s 55ms/step - loss: 0.0620 - accuracy: 0.9790 - val_loss: 0.1554 - val_accuracy: 0.9528\nEpoch 21/30\n272/272 [==============================] - 14s 53ms/step - loss: 0.0451 - accuracy: 0.9849 - val_loss: 0.2049 - val_accuracy: 0.9468\nEpoch 22/30\n272/272 [==============================] - 15s 54ms/step - loss: 0.0486 - accuracy: 0.9846 - val_loss: 0.2012 - val_accuracy: 0.9477\nEpoch 23/30\n272/272 [==============================] - 15s 54ms/step - loss: 0.0620 - accuracy: 0.9794 - val_loss: 0.1771 - val_accuracy: 0.9477\nEpoch 24/30\n272/272 [==============================] - 15s 54ms/step - loss: 0.0539 - accuracy: 0.9823 - val_loss: 0.1304 - val_accuracy: 0.9588\nEpoch 25/30\n272/272 [==============================] - 15s 54ms/step - loss: 0.0448 - accuracy: 0.9853 - val_loss: 0.1537 - val_accuracy: 0.9545\nEpoch 26/30\n272/272 [==============================] - 15s 54ms/step - loss: 0.0590 - accuracy: 0.9812 - val_loss: 0.1106 - val_accuracy: 0.9666\nEpoch 27/30\n272/272 [==============================] - 15s 53ms/step - loss: 0.0458 - accuracy: 0.9849 - val_loss: 0.1489 - val_accuracy: 0.9545\nEpoch 28/30\n272/272 [==============================] - 15s 54ms/step - loss: 0.0467 - accuracy: 0.9846 - val_loss: 0.1790 - val_accuracy: 0.9545\nEpoch 29/30\n272/272 [==============================] - 15s 53ms/step - loss: 0.0535 - accuracy: 0.9834 - val_loss: 0.1462 - val_accuracy: 0.9640\nEpoch 30/30\n272/272 [==============================] - 15s 54ms/step - loss: 0.0301 - accuracy: 0.9901 - val_loss: 0.1559 - val_accuracy: 0.9631\n","output_type":"stream"}]},{"cell_type":"code","source":"pred=np.argmax(efficientnet_model.predict(X_test),axis=1)\nytest=np.argmax(y_test,axis=1)\nprint(classification_report(pred,ytest))","metadata":{"execution":{"iopub.status.busy":"2024-01-03T21:08:26.668159Z","iopub.execute_input":"2024-01-03T21:08:26.669023Z","iopub.status.idle":"2024-01-03T21:08:31.450309Z","shell.execute_reply.started":"2024-01-03T21:08:26.668985Z","shell.execute_reply":"2024-01-03T21:08:31.449376Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"53/53 [==============================] - 4s 31ms/step\n              precision    recall  f1-score   support\n\n           0       0.97      0.97      0.97       323\n           1       0.96      0.92      0.94       342\n           2       0.90      0.98      0.94       298\n           3       0.98      0.97      0.97       344\n           4       1.00      0.99      0.99       358\n\n    accuracy                           0.96      1665\n   macro avg       0.96      0.96      0.96      1665\nweighted avg       0.96      0.96      0.96      1665\n\n","output_type":"stream"}]},{"cell_type":"code","source":"efficientnet_model.save(\"UBCeffnetv3.h5\")","metadata":{"execution":{"iopub.status.busy":"2024-01-03T21:08:39.375307Z","iopub.execute_input":"2024-01-03T21:08:39.376032Z","iopub.status.idle":"2024-01-03T21:08:40.125349Z","shell.execute_reply.started":"2024-01-03T21:08:39.376001Z","shell.execute_reply":"2024-01-03T21:08:40.124375Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n  saving_api.save_model(\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import balanced_accuracy_score\nprint(balanced_accuracy_score(ytest, pred))","metadata":{"execution":{"iopub.status.busy":"2024-01-03T21:08:31.451636Z","iopub.execute_input":"2024-01-03T21:08:31.452037Z","iopub.status.idle":"2024-01-03T21:08:31.459722Z","shell.execute_reply.started":"2024-01-03T21:08:31.452003Z","shell.execute_reply":"2024-01-03T21:08:31.458748Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"0.9618911596330934\n","output_type":"stream"}]},{"cell_type":"code","source":"import pickle\nwith open('label_encoder.pkl', 'wb') as file:\n    pickle.dump(label_encoder, file)","metadata":{"execution":{"iopub.status.busy":"2024-01-03T21:08:44.383607Z","iopub.execute_input":"2024-01-03T21:08:44.384331Z","iopub.status.idle":"2024-01-03T21:08:44.389172Z","shell.execute_reply.started":"2024-01-03T21:08:44.384297Z","shell.execute_reply":"2024-01-03T21:08:44.388173Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"!pip install albumentations","metadata":{"execution":{"iopub.status.busy":"2024-01-03T18:28:48.593074Z","iopub.execute_input":"2024-01-03T18:28:48.593344Z","iopub.status.idle":"2024-01-03T18:28:59.485924Z","shell.execute_reply.started":"2024-01-03T18:28:48.593321Z","shell.execute_reply":"2024-01-03T18:28:59.484609Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Requirement already satisfied: albumentations in /opt/conda/lib/python3.10/site-packages (1.3.1)\nRequirement already satisfied: numpy>=1.11.1 in /opt/conda/lib/python3.10/site-packages (from albumentations) (1.24.3)\nRequirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from albumentations) (1.11.4)\nRequirement already satisfied: scikit-image>=0.16.1 in /opt/conda/lib/python3.10/site-packages (from albumentations) (0.21.0)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from albumentations) (6.0.1)\nRequirement already satisfied: qudida>=0.0.4 in /opt/conda/lib/python3.10/site-packages (from albumentations) (0.0.4)\nRequirement already satisfied: opencv-python-headless>=4.1.1 in /opt/conda/lib/python3.10/site-packages (from albumentations) (4.8.1.78)\nRequirement already satisfied: scikit-learn>=0.19.1 in /opt/conda/lib/python3.10/site-packages (from qudida>=0.0.4->albumentations) (1.2.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from qudida>=0.0.4->albumentations) (4.5.0)\nRequirement already satisfied: networkx>=2.8 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.16.1->albumentations) (3.1)\nRequirement already satisfied: pillow>=9.0.1 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.16.1->albumentations) (10.1.0)\nRequirement already satisfied: imageio>=2.27 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.16.1->albumentations) (2.31.1)\nRequirement already satisfied: tifffile>=2022.8.12 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.16.1->albumentations) (2023.8.12)\nRequirement already satisfied: PyWavelets>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.16.1->albumentations) (1.4.1)\nRequirement already satisfied: packaging>=21 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.16.1->albumentations) (21.3)\nRequirement already satisfied: lazy_loader>=0.2 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.16.1->albumentations) (0.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=21->scikit-image>=0.16.1->albumentations) (3.0.9)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (1.3.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (3.2.0)\n^C\n\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}